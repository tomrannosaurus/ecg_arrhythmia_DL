{
  "config": {
    "run_id": "residual_seed123_20251211_002633",
    "timestamp": "20251211_002633",
    "datetime": "2025-12-11T00:26:33.994720",
    "model_name": "residual",
    "model_file": "model_residual.py",
    "model_class": "CNNLSTMResidual",
    "split_dir": "data/splits_20s",
    "batch_size": 64,
    "num_epochs": 100,
    "patience": 10,
    "seed": 123,
    "optimizer": "Adam",
    "learning_rate": 0.0001,
    "rnn_learning_rate": null,
    "differential_lr": false,
    "weight_decay": 0.0001,
    "freeze_cnn": false,
    "scheduler": "ReduceLROnPlateau",
    "scheduler_mode": "max",
    "scheduler_factor": 0.5,
    "scheduler_patience": 5,
    "gradient_clip_norm": 1.0,
    "save_dir": "checkpoints",
    "model_path": "checkpoints\\residual_seed123_20251211_002633.pt",
    "log_path": "checkpoints\\residual_seed123_20251211_002633_history.json",
    "results_path": "checkpoints\\residual_seed123_20251211_002633_results.json",
    "device": "cuda",
    "user": "tomra",
    "platform": "Windows",
    "torch_version": "2.9.1+cu128",
    "model_parameters": 139732,
    "criterion": "CrossEntropyLoss",
    "class_weights": [
      0.4288896322250366,
      2.8926010131835938,
      0.8009063601493835,
      13.494770050048828
    ]
  },
  "history": {
    "config": {
      "run_id": "residual_seed123_20251211_002633",
      "timestamp": "20251211_002633",
      "datetime": "2025-12-11T00:26:33.994720",
      "model_name": "residual",
      "model_file": "model_residual.py",
      "model_class": "CNNLSTMResidual",
      "split_dir": "data/splits_20s",
      "batch_size": 64,
      "num_epochs": 100,
      "patience": 10,
      "seed": 123,
      "optimizer": "Adam",
      "learning_rate": 0.0001,
      "rnn_learning_rate": null,
      "differential_lr": false,
      "weight_decay": 0.0001,
      "freeze_cnn": false,
      "scheduler": "ReduceLROnPlateau",
      "scheduler_mode": "max",
      "scheduler_factor": 0.5,
      "scheduler_patience": 5,
      "gradient_clip_norm": 1.0,
      "save_dir": "checkpoints",
      "model_path": "checkpoints\\residual_seed123_20251211_002633.pt",
      "log_path": "checkpoints\\residual_seed123_20251211_002633_history.json",
      "results_path": "checkpoints\\residual_seed123_20251211_002633_results.json",
      "device": "cuda",
      "user": "tomra",
      "platform": "Windows",
      "torch_version": "2.9.1+cu128",
      "model_parameters": 139732,
      "criterion": "CrossEntropyLoss",
      "class_weights": [
        0.4288896322250366,
        2.8926010131835938,
        0.8009063601493835,
        13.494770050048828
      ]
    },
    "train_loss": [
      1.3818682662331232,
      1.3320562686070356,
      1.2418906122150988,
      1.1966246384205204,
      1.1469067562334607,
      1.1457244854162234,
      1.1328247316402964,
      1.103238545431949,
      1.1029361645774085,
      1.0940501778432639,
      1.081248538033797,
      1.0891703615094175,
      1.0758323967456818,
      1.065908144016077,
      1.060421887600776,
      1.0696647987507357,
      1.0662243861963254,
      1.0580835826326125,
      1.0527558919816915,
      1.0358003312998478
    ],
    "train_acc": [
      0.149600806139059,
      0.3118362917603287,
      0.3450895279435703,
      0.38121075885590266,
      0.4002015347647469,
      0.39733354003565613,
      0.41857220370513915,
      0.42019998449732576,
      0.4377180063560964,
      0.44430664289589955,
      0.4120610805363925,
      0.43795054646926596,
      0.42725370126346796,
      0.43919076040617006,
      0.44562437020386014,
      0.4484923649329509,
      0.45182543988838075,
      0.4433764824432215,
      0.4408960545694132,
      0.4457793969459732
    ],
    "val_loss": [
      1.3632234253666617,
      1.300237170674584,
      1.2242059802467173,
      1.2001697976480832,
      1.1896458146246998,
      1.1837490607391705,
      1.180386635390195,
      1.1842976862734014,
      1.1865343275395306,
      1.1762826835567302,
      1.1829654709859327,
      1.1781477650458163,
      1.1772418909452178,
      1.1741303219036623,
      1.1782216314565053,
      1.176737005737695,
      1.1794034703211351,
      1.1751506064425816,
      1.180448711595752,
      1.1769163364713842
    ],
    "val_acc": [
      0.2648121387283237,
      0.3616329479768786,
      0.37789017341040465,
      0.46315028901734107,
      0.4505057803468208,
      0.48374277456647397,
      0.434971098265896,
      0.5,
      0.4570086705202312,
      0.45195086705202314,
      0.4216040462427746,
      0.4508670520231214,
      0.43027456647398843,
      0.42196531791907516,
      0.4407514450867052,
      0.4624277456647399,
      0.43713872832369943,
      0.414378612716763,
      0.4295520231213873,
      0.4436416184971098
    ],
    "val_f1": [
      0.18609138316293558,
      0.3905155970020872,
      0.3814120057188896,
      0.4191810277558491,
      0.446897124003069,
      0.4277575890847432,
      0.41222049591794063,
      0.4408288320593454,
      0.43623447092628925,
      0.45844919747724433,
      0.42217333022717213,
      0.44592047853381456,
      0.42291567696420374,
      0.4177958414808339,
      0.4315064089761115,
      0.44359219498196495,
      0.4332610199748927,
      0.4187987700851044,
      0.42505213181464413,
      0.43440589629099413
    ],
    "val_auroc": [
      0.5438353249874898,
      0.549926309153295,
      0.5608816058879053,
      0.5651321274900496,
      0.5637416265712621,
      0.5697850584104438,
      0.5721870451440694,
      0.5723410437550381,
      0.5694346247924896,
      0.5696206560592888,
      0.5704170195857055,
      0.5707554390129201,
      0.57153669342934,
      0.5722837361619981,
      0.5734369854118023,
      0.5748743905659145,
      0.5726991254089283,
      0.5734552264590347,
      0.5729097505270545,
      0.5736649396420244
    ],
    "val_sensitivity": [
      [
        0.03347799132052077,
        0.04504504504504504,
        0.7223476297968398,
        0.6170212765957447
      ],
      [
        0.33477991320520767,
        0.13963963963963963,
        0.45372460496614,
        0.5957446808510638
      ],
      [
        0.5381277123372598,
        0.4864864864864865,
        0.03724604966139955,
        0.7872340425531915
      ],
      [
        0.7154370737755734,
        0.36036036036036034,
        0.010158013544018058,
        0.8297872340425532
      ],
      [
        0.643521388716677,
        0.35585585585585583,
        0.10609480812641084,
        0.7659574468085106
      ],
      [
        0.7538747675139492,
        0.3738738738738739,
        0.007900677200902935,
        0.7021276595744681
      ],
      [
        0.6453812771233726,
        0.481981981981982,
        0.022573363431151242,
        0.7659574468085106
      ],
      [
        0.7811531308121513,
        0.32882882882882886,
        0.020316027088036117,
        0.7021276595744681
      ],
      [
        0.6738995660260384,
        0.44144144144144143,
        0.05191873589164785,
        0.723404255319149
      ],
      [
        0.6181029138251705,
        0.3963963963963964,
        0.14785553047404063,
        0.7446808510638298
      ],
      [
        0.5995040297582145,
        0.45495495495495497,
        0.07110609480812641,
        0.7659574468085106
      ],
      [
        0.6441413515189088,
        0.4144144144144144,
        0.09255079006772009,
        0.7446808510638298
      ],
      [
        0.6243025418474891,
        0.44594594594594594,
        0.056433408577878104,
        0.7446808510638298
      ],
      [
        0.6032238065716057,
        0.4774774774774775,
        0.05869074492099323,
        0.7872340425531915
      ],
      [
        0.6367017978921264,
        0.45495495495495497,
        0.06433408577878104,
        0.7446808510638298
      ],
      [
        0.6751394916305021,
        0.43243243243243246,
        0.06772009029345373,
        0.7446808510638298
      ],
      [
        0.6267823930564166,
        0.4369369369369369,
        0.0744920993227991,
        0.7659574468085106
      ],
      [
        0.5796652200867948,
        0.4954954954954955,
        0.07562076749435666,
        0.7446808510638298
      ],
      [
        0.6162430254184749,
        0.4594594594594595,
        0.06433408577878104,
        0.7659574468085106
      ],
      [
        0.6404215747055176,
        0.45045045045045046,
        0.06772009029345373,
        0.7446808510638298
      ]
    ],
    "val_specificity": [
      [
        0.9800865800865801,
        0.9721131186174391,
        0.2784272051009564,
        0.7857405365674385
      ],
      [
        0.7402597402597403,
        0.9241948153967007,
        0.5536663124335813,
        0.8404998162440279
      ],
      [
        0.5904761904761905,
        0.6767478397486253,
        0.9521785334750266,
        0.87651598676957
      ],
      [
        0.43203463203463205,
        0.821681068342498,
        0.9867162592986185,
        0.8710033076074972
      ],
      [
        0.5056277056277056,
        0.821681068342498,
        0.900106269925611,
        0.8868063212054392
      ],
      [
        0.3948051948051948,
        0.8299293008641005,
        0.9946865037194474,
        0.8945240720323411
      ],
      [
        0.5186147186147186,
        0.746661429693637,
        0.9856535600425079,
        0.87651598676957
      ],
      [
        0.3645021645021645,
        0.8629222309505106,
        0.9835281615302869,
        0.9007717750826902
      ],
      [
        0.49437229437229435,
        0.786331500392773,
        0.9601487778958555,
        0.8897464167585446
      ],
      [
        0.548051948051948,
        0.8256087981146897,
        0.8602550478214666,
        0.8941565600882029
      ],
      [
        0.554978354978355,
        0.7572663000785546,
        0.9388947927736451,
        0.8699007717750827
      ],
      [
        0.5212121212121212,
        0.8106834249803614,
        0.9165781083953242,
        0.8794560823226755
      ],
      [
        0.5341991341991342,
        0.7631578947368421,
        0.9548352816153028,
        0.8710033076074972
      ],
      [
        0.5489177489177489,
        0.7439120188531029,
        0.9543039319872476,
        0.8746784270488791
      ],
      [
        0.5255411255411255,
        0.7639434406912804,
        0.9553666312433581,
        0.8842337375964718
      ],
      [
        0.48744588744588746,
        0.7965435978004713,
        0.9436769394261424,
        0.9000367511944138
      ],
      [
        0.5359307359307359,
        0.7851531814611155,
        0.9399574920297555,
        0.8669606762219773
      ],
      [
        0.5766233766233766,
        0.716025137470542,
        0.9378320935175345,
        0.8926865123116501
      ],
      [
        0.5428571428571428,
        0.7596229379418696,
        0.9500531349628055,
        0.8732083792723263
      ],
      [
        0.5246753246753246,
        0.7706205813040062,
        0.9489904357066951,
        0.8857037853730246
      ]
    ],
    "learning_rate": [
      0.0001,
      0.0001,
      0.0001,
      0.0001,
      0.0001,
      0.0001,
      0.0001,
      0.0001,
      5e-05,
      5e-05,
      5e-05,
      5e-05,
      5e-05,
      2.5e-05,
      2.5e-05,
      2.5e-05,
      1.25e-05,
      1.25e-05,
      1.25e-05,
      6.25e-06
    ],
    "learning_rate_dict": [
      null,
      null,
      null,
      null,
      null,
      null,
      null,
      null,
      null,
      null,
      null,
      null,
      null,
      null,
      null,
      null,
      null,
      null,
      null,
      null
    ],
    "epochs_completed": 20,
    "best_epoch": 10,
    "best_val_f1": 0.45844919747724433,
    "stopped_early": true,
    "start_time": "2025-12-11T00:26:35.768130",
    "end_time": "2025-12-11T00:36:21.595819"
  },
  "test": {
    "loss": 1.1152390946041455,
    "accuracy": 0.43820224719101125,
    "f1": 0.44180120459409217,
    "auroc": 0.5724075379367979,
    "sensitivity": [
      0.5942211055276382,
      0.43209876543209874,
      0.12844036697247707,
      0.8846153846153846
    ],
    "specificity": [
      0.5629820051413882,
      0.8207472178060413,
      0.8547959724430313,
      0.8836350203176949
    ]
  }
}